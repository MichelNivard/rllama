% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llamar.R
\name{llama}
\alias{llama}
\title{Ask llama to respond to the given prompt}
\usage{
llama(
  ctx,
  prompt,
  n = 50,
  repeat_penalty = 1.05,
  greedy = TRUE,
  temp = 0.8,
  verbose = TRUE
)
}
\arguments{
\item{ctx}{llama context (created using \code{llama_init()})}

\item{prompt}{character string}

\item{n}{maximum number of tokens to emit.}

\item{repeat_penalty}{penalty applied to tokens to avoid repetition. 
Default: 1.05.   Use \code{1} for no penalty, and higher numbers to
avoid repetition more.}

\item{greedy}{logical. Simply take the highest probability token as the 
next token. default: TRUE.    If FALSE, then use a temperature 
based selection technique.}

\item{temp}{default: 0.8.  Controls the probabilistic(?) non-greedy selection
of the next token.  Only used if \code{greedy = FALSE}}

\item{verbose}{logical. Output tokens as they are generated. Default: TRUE}
}
\value{
Invisibly returns the entire response as a single string
}
\description{
Ask llama to respond to the given prompt
}
